{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project3 - 二元分类器\n",
    "\n",
    "本部分实现的逻辑回归的二元分类，同时使用了BGD,SGD,MBGD三种不同方法。使用的数据集是糖尿病数据集pima-indians-diabetes。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# 用于对比sklearn结果所需的库\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 切割数据为训练集和测试集，及归一化\n",
    "def split_data(data):\n",
    "    m = 500\n",
    "    f = 8\n",
    "\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "\n",
    "    # 归一化数据\n",
    "    x = (x-np.mean(x))/np.std(x)\n",
    "\n",
    "    new_X_train = x[:m,:f]\n",
    "    new_X_train = np.c_[np.ones(len(new_X_train),dtype='int64'),new_X_train]\n",
    "    new_y_train = y[:m]\n",
    "    new_X_test = x[m:,:f]\n",
    "    new_X_test = np.c_[np.ones(len(new_X_test),dtype='int64'),new_X_test]\n",
    "    new_y_test = y[m:]\n",
    "\n",
    "    return new_X_train,new_X_test,new_y_train,new_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化学习率和迭代次数\n",
    "alpha = 0.005\n",
    "iters = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用了BGD,SGD,MBGD三种不同的梯度下降方式来训练模型，并使用了L2正则化。在MBGD中，每个批次包含100个数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGD\n",
    "def BGD(X,y,B,alpha,iterations):\n",
    "    x_transposed = X.T\n",
    "    m = len(y)\n",
    "\n",
    "    for itreation in range(iterations):\n",
    "        h = sigmoid(np.dot(X,B))\n",
    "        loss = h - y\n",
    "\n",
    "        gradient = x_transposed.dot(loss) / m\n",
    "        # L2正则化\n",
    "        b = B[0]\n",
    "        B = (1 - alpha * 0.5 / m) * B - alpha * gradient\n",
    "        B[0] = b - alpha * gradient [0] / m\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SGD\n",
    "def SGD(X,y,B,alpha,iterations):\n",
    "    m = len(y)\n",
    "\n",
    "    for itreation in range(iterations):\n",
    "        for i in range(m):\n",
    "            index=int(random.uniform(0,m))\n",
    "            h = sigmoid(np.dot(X[index],B))\n",
    "            loss = h - y[index]\n",
    "\n",
    "            # L2正则化\n",
    "            b = B[0]\n",
    "            B = (1 - alpha * 0.5) * B - alpha * (loss * X[index])\n",
    "            B[0] = b - alpha * alpha * (loss * X[index]) [0]\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MBSG\n",
    "def MBGD(X,y,B,alpha,batch_size,iterations):\n",
    "    m = len(y)\n",
    "\n",
    "    for itreation in range(iterations):\n",
    "        batch = int(np.ceil(m / batch_size))\n",
    "        for i in range(batch):\n",
    "            batch_id = batch_size * i\n",
    "            x_batch = X[batch_id:min(batch_id+batch_size,len(X))]\n",
    "            y_batch = y[batch_id:min(batch_id+batch_size,len(y))]\n",
    "\n",
    "            h = sigmoid(np.dot(x_batch,B))\n",
    "            loss = h - y_batch\n",
    "\n",
    "            b = B[0]\n",
    "            bm = len(x_batch)\n",
    "\n",
    "            B = (1 - alpha * 0.5 / bm) * B - alpha * (np.dot(x_batch.T,loss)) / bm\n",
    "            B[0] = b - alpha * (np.dot(x_batch.T,loss)) [0] / bm\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,B):\n",
    "    return sigmoid(np.dot(x,B)).T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行\n",
    "\n",
    "分别使用BGD,SGD,MBGD三种方式进行训练，同时使用测试集来测试三种方式的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGD准确率为: 0.7910447761194029\n",
      "SGD准确率为: 0.6828358208955224\n",
      "MBGD准确率为: 0.8134328358208955\n"
     ]
    }
   ],
   "source": [
    "# 运行\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"binaryLR.csv\")\n",
    "\n",
    "# 归一化及切割数据\n",
    "X_train,X_test,y_train,y_test = split_data(data.values)\n",
    "\n",
    "B = np.ones(X_train.shape[1])\n",
    "\n",
    "# BGD\n",
    "new_beta1 = BGD(X_train,y_train,B,alpha,iters)\n",
    "new_beta1 = np.atleast_2d(new_beta1).reshape((9,1))\n",
    "y_pred1 = np.round(predict(X_test,new_beta1))\n",
    "print(\"BGD准确率为:\",np.mean(np.equal(y_pred1,y_test)))\n",
    "\n",
    "# SGD\n",
    "new_beta2 = SGD(X_train,y_train,B,alpha,iters)\n",
    "new_beta2 = np.atleast_2d(new_beta2).reshape((9,1))\n",
    "y_pred2 = np.round(predict(X_test,new_beta2))\n",
    "print(\"SGD准确率为:\",np.mean(np.equal(y_pred2,y_test)))\n",
    "\n",
    "# MBGD\n",
    "new_beta3 = MBGD(X_train,y_train,B,alpha,100,iters)\n",
    "new_beta3 = np.atleast_2d(new_beta3).reshape((9,1))\n",
    "y_pred3 = np.round(predict(X_test,new_beta3))\n",
    "print(\"MBGD准确率为:\",np.mean(np.equal(y_pred3,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn方式\n",
    "\n",
    "调用sklearn提供的方法训练，并使用测试集测试该方法的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGD准确率为: 0.7910447761194029\n",
      "SGD准确率为: 0.6828358208955224\n",
      "MBGD准确率为: 0.8134328358208955\n",
      "sklearn准确率为: 0.8097014925373134\n"
     ]
    }
   ],
   "source": [
    "#与sklearn比较\n",
    "sk_data = pd.read_csv(\"binaryLR.csv\")\n",
    "sc = StandardScaler()\n",
    "sk_data = sc.fit_transform(sk_data)\n",
    "sk_x = sk_data[:,:-1]\n",
    "sk_y = sk_data[:,-1]\n",
    "m = 500\n",
    "f = 8\n",
    "\n",
    "X_train = sk_x[:m,:f]\n",
    "X_train = np.c_[np.ones(len(X_train),dtype='int64'),X_train]\n",
    "\n",
    "Y_train = sk_y[:m]\n",
    "\n",
    "X_test = sk_x[m:,:f]\n",
    "X_test = np.c_[np.ones(len(X_test),dtype='int64'),X_test]\n",
    "\n",
    "Y_test = sk_y[m:]\n",
    "\n",
    "model = linear_model.LogisticRegression(penalty='l2',max_iter=2000)\n",
    "model.fit(X_train,Y_train.astype('int'))\n",
    "print(\"sklearn准确率为:\",model.score(X_test,Y_test.astype('int')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (project1)",
   "language": "python",
   "name": "pycharm-449fcbdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}